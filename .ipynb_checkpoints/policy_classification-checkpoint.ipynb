{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy Policies Classification\n",
    "### Author: Valentina Chacon Buitrago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Valentina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Valentina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import abspath, isfile, join\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset():\n",
    "    types = ['legit', 'rogue']\n",
    "    for i in types:\n",
    "        \n",
    "        current_dir = abspath(join('privacy_policies', i))\n",
    "        \n",
    "        for f in listdir(current_dir):\n",
    "            file = join(current_dir,f)\n",
    "            if isfile(file) and f.endswith('.txt'):\n",
    "                open_file = open(file, 'r', encoding='windows-1252')\n",
    "                text_data = open_file.read()\n",
    "                \n",
    "build_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data = load_files(os.path.abspath('privacy_policies'))\n",
    "x,y = page_data.data, page_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "documents = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    # Remove all break line characters\n",
    "    document = str(x[i], 'mac_roman')\n",
    "    document = document.replace('\\r', ' ').replace('\\n', ' ')\n",
    "\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', document)\n",
    "    \n",
    "    # Remove all single characters \n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Remove all numbers\n",
    "    document = re.sub(r'\\d+', '', document)\n",
    "   \n",
    "    # Substitute multiple spaces with a single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Convert document to lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1. Bag of words - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Modify just the parameter n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators 10\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 100\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 200\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 300\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 500\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 800\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 1000\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 1200\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 2000\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "n_estimators 5000\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "# Convert text to numbers and find TFIDF\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "# Select training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "estimators = [10,100,200,300,500,800,1000,1200,2000,5000]\n",
    "for i in range(len(estimators)):\n",
    "# Train the classification model\n",
    "    classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('n_estimators ' + str(estimators[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Modify just the parameter max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features 10\n",
      "[[24  5]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.76        29\n",
      "           1       0.71      0.55      0.62        22\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.71      0.69      0.69        51\n",
      "weighted avg       0.71      0.71      0.70        51\n",
      "\n",
      "0.7058823529411765\n",
      "max_features 100\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_features 200\n",
      "[[28  1]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        29\n",
      "           1       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.80      0.71      0.71        51\n",
      "weighted avg       0.79      0.75      0.72        51\n",
      "\n",
      "0.7450980392156863\n",
      "max_features 300\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_features 500\n",
      "[[28  1]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84        29\n",
      "           1       0.92      0.55      0.69        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.83      0.76      0.76        51\n",
      "weighted avg       0.82      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 800\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 1000\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 1200\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "max_features 2000\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "max_features 5000\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n"
     ]
    }
   ],
   "source": [
    "features = [10,100,200,300,500,800,1000,1200,2000,5000]\n",
    "\n",
    "for i in range(len(features)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=features[i], min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_features ' + str(features[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Modify just the parameter min_df\n",
    "min_df is used for removing terms that appear too infrequently.\n",
    "- min_df = 5 means \"ignore terms that appear in less than 5 documents\".\n",
    "- The default min_df is 1, which means \"ignore terms that appear in less than 1 document\". Thus, the default setting does not ignore any terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df 1\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "min_df 10\n",
      "[[28  1]\n",
      " [13  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80        29\n",
      "           1       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.79      0.69      0.68        51\n",
      "weighted avg       0.78      0.73      0.70        51\n",
      "\n",
      "0.7254901960784313\n",
      "min_df 20\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 30\n",
      "[[28  1]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.82        29\n",
      "           1       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.82      0.73      0.74        51\n",
      "weighted avg       0.80      0.76      0.75        51\n",
      "\n",
      "0.7647058823529411\n",
      "min_df 40\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "min_df 50\n",
      "[[29  0]\n",
      " [13  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        29\n",
      "           1       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.85      0.70      0.70        51\n",
      "weighted avg       0.82      0.75      0.71        51\n",
      "\n",
      "0.7450980392156863\n",
      "min_df 80\n",
      "[[28  1]\n",
      " [13  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80        29\n",
      "           1       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.79      0.69      0.68        51\n",
      "weighted avg       0.78      0.73      0.70        51\n",
      "\n",
      "0.7254901960784313\n",
      "min_df 90\n",
      "[[27  2]\n",
      " [14  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.93      0.77        29\n",
      "           1       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.69        51\n",
      "   macro avg       0.73      0.65      0.64        51\n",
      "weighted avg       0.72      0.69      0.65        51\n",
      "\n",
      "0.6862745098039216\n"
     ]
    }
   ],
   "source": [
    "df_min = [1,10,20,30,40,50,80,90]\n",
    "\n",
    "for i in range(len(df_min)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=df_min[i], max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('min_df ' + str(df_min[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df 0.1\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 0.2\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 0.3\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 0.4\n",
      "[[27  2]\n",
      " [13  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.78        29\n",
      "           1       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.75      0.67      0.66        51\n",
      "weighted avg       0.74      0.71      0.68        51\n",
      "\n",
      "0.7058823529411765\n",
      "min_df 0.5\n",
      "[[29  0]\n",
      " [14  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.81        29\n",
      "           1       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.84      0.68      0.67        51\n",
      "weighted avg       0.81      0.73      0.69        51\n",
      "\n",
      "0.7254901960784313\n",
      "min_df 0.6\n",
      "[[26  3]\n",
      " [14  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.90      0.75        29\n",
      "           1       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.67        51\n",
      "   macro avg       0.69      0.63      0.62        51\n",
      "weighted avg       0.68      0.67      0.64        51\n",
      "\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "df_min = [0.1,0.2,0.3,0.4,0.5,0.6]\n",
    "\n",
    "for i in range(len(df_min)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=df_min[i], max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('min_df ' + str(df_min[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Modify just the parameter max_df\n",
    "max_df is used for removing terms that appear too frequently, also known as \"corpus-specific stop words.\n",
    "- max_df = 25 means \"ignore terms that appear in more than 25 documents\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 1\n",
      "[[ 0 29]\n",
      " [ 0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        29\n",
      "           1       0.43      1.00      0.60        22\n",
      "\n",
      "    accuracy                           0.43        51\n",
      "   macro avg       0.22      0.50      0.30        51\n",
      "weighted avg       0.19      0.43      0.26        51\n",
      "\n",
      "0.43137254901960786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 10\n",
      "[[12 17]\n",
      " [ 1 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.41      0.57        29\n",
      "           1       0.55      0.95      0.70        22\n",
      "\n",
      "    accuracy                           0.65        51\n",
      "   macro avg       0.74      0.68      0.64        51\n",
      "weighted avg       0.76      0.65      0.63        51\n",
      "\n",
      "0.6470588235294118\n",
      "max_df 20\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 30\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 40\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_df 50\n",
      "[[28  1]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.82        29\n",
      "           1       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.82      0.73      0.74        51\n",
      "weighted avg       0.80      0.76      0.75        51\n",
      "\n",
      "0.7647058823529411\n",
      "max_df 80\n",
      "[[28  1]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85        29\n",
      "           1       0.93      0.59      0.72        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.84      0.78      0.79        51\n",
      "weighted avg       0.83      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 90\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n"
     ]
    }
   ],
   "source": [
    "df_max = [1,10,20,30,40,50,80,90]\n",
    "\n",
    "for i in range(len(df_max)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=1, max_df=df_max[i], stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_df ' + str(df_max[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_df = 0.50 means \"ignore terms that appear in more than 50% of the documents\".\n",
    "- The default max_df is 1.0, which means \"ignore terms that appear in more than 100% of the documents\". Thus, the default setting does not ignore any terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 0.1\n",
      "[[20  9]\n",
      " [ 8 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70        29\n",
      "           1       0.61      0.64      0.62        22\n",
      "\n",
      "    accuracy                           0.67        51\n",
      "   macro avg       0.66      0.66      0.66        51\n",
      "weighted avg       0.67      0.67      0.67        51\n",
      "\n",
      "0.6666666666666666\n",
      "max_df 0.2\n",
      "[[26  3]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.78        29\n",
      "           1       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.73      0.68      0.67        51\n",
      "weighted avg       0.72      0.71      0.69        51\n",
      "\n",
      "0.7058823529411765\n",
      "max_df 0.3\n",
      "[[27  2]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83        29\n",
      "           1       0.87      0.59      0.70        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.81      0.76      0.77        51\n",
      "weighted avg       0.80      0.78      0.78        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_df 0.4\n",
      "[[29  0]\n",
      " [ 6 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        29\n",
      "           1       1.00      0.73      0.84        22\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.91      0.86      0.87        51\n",
      "weighted avg       0.90      0.88      0.88        51\n",
      "\n",
      "0.8823529411764706\n",
      "max_df 0.5\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 0.6\n",
      "[[29  0]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        29\n",
      "           1       1.00      0.59      0.74        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.88      0.80      0.80        51\n",
      "weighted avg       0.87      0.82      0.81        51\n",
      "\n",
      "0.8235294117647058\n",
      "max_df 0.7\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_df 0.8\n",
      "[[28  1]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85        29\n",
      "           1       0.93      0.59      0.72        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.84      0.78      0.79        51\n",
      "weighted avg       0.83      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 0.9\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n"
     ]
    }
   ],
   "source": [
    "df_max = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for i in range(len(df_max)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=0.1, max_df=df_max[i], stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_df ' + str(df_max[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2. Bag of words - SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Modify just the parameter loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss hinge\n",
      "[[28  1]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90        29\n",
      "           1       0.94      0.77      0.85        22\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.90      0.87      0.88        51\n",
      "weighted avg       0.89      0.88      0.88        51\n",
      "\n",
      "0.8823529411764706\n",
      "loss log\n",
      "[[28  1]\n",
      " [ 7 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88        29\n",
      "           1       0.94      0.68      0.79        22\n",
      "\n",
      "    accuracy                           0.84        51\n",
      "   macro avg       0.87      0.82      0.83        51\n",
      "weighted avg       0.86      0.84      0.84        51\n",
      "\n",
      "0.8431372549019608\n",
      "loss modified_huber\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "loss squared_hinge\n",
      "[[28  1]\n",
      " [ 8 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86        29\n",
      "           1       0.93      0.64      0.76        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.86      0.80      0.81        51\n",
      "weighted avg       0.84      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "loss perceptron\n",
      "[[28  1]\n",
      " [ 6 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89        29\n",
      "           1       0.94      0.73      0.82        22\n",
      "\n",
      "    accuracy                           0.86        51\n",
      "   macro avg       0.88      0.85      0.85        51\n",
      "weighted avg       0.87      0.86      0.86        51\n",
      "\n",
      "0.8627450980392157\n",
      "loss squared_loss\n",
      "[[ 7 22]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.24      0.31        29\n",
      "           1       0.37      0.59      0.46        22\n",
      "\n",
      "    accuracy                           0.39        51\n",
      "   macro avg       0.40      0.42      0.38        51\n",
      "weighted avg       0.41      0.39      0.37        51\n",
      "\n",
      "0.39215686274509803\n",
      "loss huber\n",
      "[[26  3]\n",
      " [ 3 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        29\n",
      "           1       0.86      0.86      0.86        22\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.88      0.88      0.88        51\n",
      "weighted avg       0.88      0.88      0.88        51\n",
      "\n",
      "0.8823529411764706\n",
      "loss epsilon_insensitive\n",
      "[[ 7 22]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.24      0.37        29\n",
      "           1       0.48      0.91      0.62        22\n",
      "\n",
      "    accuracy                           0.53        51\n",
      "   macro avg       0.63      0.58      0.50        51\n",
      "weighted avg       0.65      0.53      0.48        51\n",
      "\n",
      "0.5294117647058824\n",
      "loss squared_epsilon_insensitive\n",
      "[[19 10]\n",
      " [16  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.66      0.59        29\n",
      "           1       0.38      0.27      0.32        22\n",
      "\n",
      "    accuracy                           0.49        51\n",
      "   macro avg       0.46      0.46      0.45        51\n",
      "weighted avg       0.47      0.49      0.47        51\n",
      "\n",
      "0.49019607843137253\n"
     ]
    }
   ],
   "source": [
    "# Convert text to numbers and find TFIDF\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "# Select training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "loss = ['hinge','log','modified_huber','squared_hinge','perceptron','squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "for i in range(len(loss)):\n",
    "# Train the classification model\n",
    "    classifier = SGDClassifier(loss=loss[i])\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('loss ' + str(loss[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Modify just the parameter max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features 10\n",
      "[[12 17]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.41      0.56        29\n",
      "           1       0.54      0.91      0.68        22\n",
      "\n",
      "    accuracy                           0.63        51\n",
      "   macro avg       0.70      0.66      0.62        51\n",
      "weighted avg       0.72      0.63      0.61        51\n",
      "\n",
      "0.6274509803921569\n",
      "max_features 100\n",
      "[[25  4]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        29\n",
      "           1       0.76      0.59      0.67        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.75      0.73      0.73        51\n",
      "weighted avg       0.75      0.75      0.74        51\n",
      "\n",
      "0.7450980392156863\n",
      "max_features 200\n",
      "[[21  8]\n",
      " [ 4 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78        29\n",
      "           1       0.69      0.82      0.75        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.77      0.77      0.76        51\n",
      "weighted avg       0.78      0.76      0.77        51\n",
      "\n",
      "0.7647058823529411\n",
      "max_features 300\n",
      "[[21  8]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.81        29\n",
      "           1       0.71      0.91      0.80        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.81      0.82      0.80        51\n",
      "weighted avg       0.83      0.80      0.80        51\n",
      "\n",
      "0.803921568627451\n",
      "max_features 500\n",
      "[[28  1]\n",
      " [ 8 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86        29\n",
      "           1       0.93      0.64      0.76        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.86      0.80      0.81        51\n",
      "weighted avg       0.84      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "max_features 800\n",
      "[[25  4]\n",
      " [ 4 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        29\n",
      "           1       0.82      0.82      0.82        22\n",
      "\n",
      "    accuracy                           0.84        51\n",
      "   macro avg       0.84      0.84      0.84        51\n",
      "weighted avg       0.84      0.84      0.84        51\n",
      "\n",
      "0.8431372549019608\n",
      "max_features 1000\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "max_features 1200\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_features 2000\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 5000\n",
      "[[26  3]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        29\n",
      "           1       0.85      0.77      0.81        22\n",
      "\n",
      "    accuracy                           0.84        51\n",
      "   macro avg       0.84      0.83      0.84        51\n",
      "weighted avg       0.84      0.84      0.84        51\n",
      "\n",
      "0.8431372549019608\n"
     ]
    }
   ],
   "source": [
    "features = [10,100,200,300,500,800,1000,1200,2000,5000]\n",
    "\n",
    "for i in range(len(features)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=features[i], min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model, by default classifier has parameter loss='hinge'\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_features ' + str(features[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Modify just the parameter min_df\n",
    "min_df is used for removing terms that appear too infrequently.\n",
    "- min_df = 5 means \"ignore terms that appear in less than 5 documents\".\n",
    "- The default min_df is 1, which means \"ignore terms that appear in less than 1 document\". Thus, the default setting does not ignore any terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df 1\n",
      "[[25  4]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85        29\n",
      "           1       0.81      0.77      0.79        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.82      0.82      0.82        51\n",
      "weighted avg       0.82      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "min_df 10\n",
      "[[25  4]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85        29\n",
      "           1       0.81      0.77      0.79        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.82      0.82      0.82        51\n",
      "weighted avg       0.82      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "min_df 20\n",
      "[[27  2]\n",
      " [ 6 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        29\n",
      "           1       0.89      0.73      0.80        22\n",
      "\n",
      "    accuracy                           0.84        51\n",
      "   macro avg       0.85      0.83      0.84        51\n",
      "weighted avg       0.85      0.84      0.84        51\n",
      "\n",
      "0.8431372549019608\n",
      "min_df 30\n",
      "[[24  5]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        29\n",
      "           1       0.77      0.77      0.77        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.80      0.80      0.80        51\n",
      "weighted avg       0.80      0.80      0.80        51\n",
      "\n",
      "0.803921568627451\n",
      "min_df 40\n",
      "[[26  3]\n",
      " [ 6 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        29\n",
      "           1       0.84      0.73      0.78        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.83      0.81      0.82        51\n",
      "weighted avg       0.83      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "min_df 50\n",
      "[[27  2]\n",
      " [ 7 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86        29\n",
      "           1       0.88      0.68      0.77        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.84      0.81      0.81        51\n",
      "weighted avg       0.83      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "min_df 80\n",
      "[[28  1]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        29\n",
      "           1       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.80      0.71      0.71        51\n",
      "weighted avg       0.79      0.75      0.72        51\n",
      "\n",
      "0.7450980392156863\n",
      "min_df 90\n",
      "[[20  9]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69        29\n",
      "           1       0.59      0.59      0.59        22\n",
      "\n",
      "    accuracy                           0.65        51\n",
      "   macro avg       0.64      0.64      0.64        51\n",
      "weighted avg       0.65      0.65      0.65        51\n",
      "\n",
      "0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "df_min = [1,10,20,30,40,50,80,90]\n",
    "\n",
    "for i in range(len(df_min)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=df_min[i], max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('min_df ' + str(df_min[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df 0.1\n",
      "[[16 13]\n",
      " [ 1 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.55      0.70        29\n",
      "           1       0.62      0.95      0.75        22\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.78      0.75      0.72        51\n",
      "weighted avg       0.80      0.73      0.72        51\n",
      "\n",
      "0.7254901960784313\n",
      "min_df 0.2\n",
      "[[23  6]\n",
      " [ 3 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.84        29\n",
      "           1       0.76      0.86      0.81        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.82      0.83      0.82        51\n",
      "weighted avg       0.83      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "min_df 0.3\n",
      "[[23  6]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81        29\n",
      "           1       0.74      0.77      0.76        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.78      0.78      0.78        51\n",
      "weighted avg       0.79      0.78      0.78        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 0.4\n",
      "[[24  5]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.77        29\n",
      "           1       0.72      0.59      0.65        22\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.72      0.71      0.71        51\n",
      "weighted avg       0.73      0.73      0.72        51\n",
      "\n",
      "0.7254901960784313\n",
      "min_df 0.5\n",
      "[[22  7]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        29\n",
      "           1       0.63      0.55      0.59        22\n",
      "\n",
      "    accuracy                           0.67        51\n",
      "   macro avg       0.66      0.65      0.65        51\n",
      "weighted avg       0.66      0.67      0.66        51\n",
      "\n",
      "0.6666666666666666\n",
      "min_df 0.6\n",
      "[[22  7]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.76      0.70        29\n",
      "           1       0.59      0.45      0.51        22\n",
      "\n",
      "    accuracy                           0.63        51\n",
      "   macro avg       0.62      0.61      0.61        51\n",
      "weighted avg       0.62      0.63      0.62        51\n",
      "\n",
      "0.6274509803921569\n"
     ]
    }
   ],
   "source": [
    "df_min = [0.1,0.2,0.3,0.4,0.5,0.6]\n",
    "\n",
    "for i in range(len(df_min)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=df_min[i], max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('min_df ' + str(df_min[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Modify just the parameter max_df\n",
    "max_df is used for removing terms that appear too frequently, also known as \"corpus-specific stop words.\n",
    "- max_df = 25 means \"ignore terms that appear in more than 25 documents\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 1\n",
      "[[ 0 29]\n",
      " [ 0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        29\n",
      "           1       0.43      1.00      0.60        22\n",
      "\n",
      "    accuracy                           0.43        51\n",
      "   macro avg       0.22      0.50      0.30        51\n",
      "weighted avg       0.19      0.43      0.26        51\n",
      "\n",
      "0.43137254901960786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 10\n",
      "[[13 16]\n",
      " [ 1 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.45      0.60        29\n",
      "           1       0.57      0.95      0.71        22\n",
      "\n",
      "    accuracy                           0.67        51\n",
      "   macro avg       0.75      0.70      0.66        51\n",
      "weighted avg       0.77      0.67      0.65        51\n",
      "\n",
      "0.6666666666666666\n",
      "max_df 20\n",
      "[[11 18]\n",
      " [ 0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.38      0.55        29\n",
      "           1       0.55      1.00      0.71        22\n",
      "\n",
      "    accuracy                           0.65        51\n",
      "   macro avg       0.78      0.69      0.63        51\n",
      "weighted avg       0.81      0.65      0.62        51\n",
      "\n",
      "0.6470588235294118\n",
      "max_df 30\n",
      "[[25  4]\n",
      " [ 8 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81        29\n",
      "           1       0.78      0.64      0.70        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.77      0.75      0.75        51\n",
      "weighted avg       0.77      0.76      0.76        51\n",
      "\n",
      "0.7647058823529411\n",
      "max_df 40\n",
      "[[27  2]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83        29\n",
      "           1       0.87      0.59      0.70        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.81      0.76      0.77        51\n",
      "weighted avg       0.80      0.78      0.78        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_df 50\n",
      "[[24  5]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        29\n",
      "           1       0.77      0.77      0.77        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.80      0.80      0.80        51\n",
      "weighted avg       0.80      0.80      0.80        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 80\n",
      "[[22  7]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83        29\n",
      "           1       0.74      0.91      0.82        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.83      0.83      0.82        51\n",
      "weighted avg       0.84      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "max_df 90\n",
      "[[28  1]\n",
      " [ 8 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86        29\n",
      "           1       0.93      0.64      0.76        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.86      0.80      0.81        51\n",
      "weighted avg       0.84      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "df_max = [1,10,20,30,40,50,80,90]\n",
    "\n",
    "for i in range(len(df_max)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=1, max_df=df_max[i], stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_df ' + str(df_max[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 0.1\n",
      "[[18 11]\n",
      " [ 4 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.62      0.71        29\n",
      "           1       0.62      0.82      0.71        22\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.72      0.72      0.71        51\n",
      "weighted avg       0.73      0.71      0.71        51\n",
      "\n",
      "0.7058823529411765\n",
      "max_df 0.2\n",
      "[[22  7]\n",
      " [ 6 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77        29\n",
      "           1       0.70      0.73      0.71        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.74      0.74      0.74        51\n",
      "weighted avg       0.75      0.75      0.75        51\n",
      "\n",
      "0.7450980392156863\n",
      "max_df 0.3\n",
      "[[24  5]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        29\n",
      "           1       0.77      0.77      0.77        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.80      0.80      0.80        51\n",
      "weighted avg       0.80      0.80      0.80        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 0.4\n",
      "[[24  5]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87        29\n",
      "           1       0.80      0.91      0.85        22\n",
      "\n",
      "    accuracy                           0.86        51\n",
      "   macro avg       0.86      0.87      0.86        51\n",
      "weighted avg       0.87      0.86      0.86        51\n",
      "\n",
      "0.8627450980392157\n",
      "max_df 0.5\n",
      "[[29  0]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        29\n",
      "           1       1.00      0.77      0.87        22\n",
      "\n",
      "    accuracy                           0.90        51\n",
      "   macro avg       0.93      0.89      0.90        51\n",
      "weighted avg       0.92      0.90      0.90        51\n",
      "\n",
      "0.9019607843137255\n",
      "max_df 0.6\n",
      "[[21  8]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.81        29\n",
      "           1       0.71      0.91      0.80        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.81      0.82      0.80        51\n",
      "weighted avg       0.83      0.80      0.80        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 0.7\n",
      "[[20  9]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.69      0.78        29\n",
      "           1       0.69      0.91      0.78        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.80      0.80      0.78        51\n",
      "weighted avg       0.81      0.78      0.78        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_df 0.8\n",
      "[[26  3]\n",
      " [ 3 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        29\n",
      "           1       0.86      0.86      0.86        22\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.88      0.88      0.88        51\n",
      "weighted avg       0.88      0.88      0.88        51\n",
      "\n",
      "0.8823529411764706\n",
      "max_df 0.9\n",
      "[[25  4]\n",
      " [ 7 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82        29\n",
      "           1       0.79      0.68      0.73        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.79      0.77      0.78        51\n",
      "weighted avg       0.78      0.78      0.78        51\n",
      "\n",
      "0.7843137254901961\n"
     ]
    }
   ],
   "source": [
    "df_max = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for i in range(len(df_max)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=0.1, max_df=df_max[i], stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_df ' + str(df_max[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3. Bag of words - K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Modify just the parameter n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors 1\n",
      "[[21  8]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76        29\n",
      "           1       0.68      0.77      0.72        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.74      0.75      0.74        51\n",
      "weighted avg       0.75      0.75      0.75        51\n",
      "\n",
      "0.7450980392156863\n",
      "neighbors 3\n",
      "[[28  1]\n",
      " [14  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.79        29\n",
      "           1       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.78      0.66      0.65        51\n",
      "weighted avg       0.76      0.71      0.67        51\n",
      "\n",
      "0.7058823529411765\n",
      "neighbors 5\n",
      "[[28  1]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.82        29\n",
      "           1       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.82      0.73      0.74        51\n",
      "weighted avg       0.80      0.76      0.75        51\n",
      "\n",
      "0.7647058823529411\n",
      "neighbors 8\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "neighbors 10\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "neighbors 20\n",
      "[[28  1]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.82        29\n",
      "           1       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.82      0.73      0.74        51\n",
      "weighted avg       0.80      0.76      0.75        51\n",
      "\n",
      "0.7647058823529411\n",
      "neighbors 50\n",
      "[[29  0]\n",
      " [19  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75        29\n",
      "           1       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.63        51\n",
      "   macro avg       0.80      0.57      0.50        51\n",
      "weighted avg       0.77      0.63      0.53        51\n",
      "\n",
      "0.6274509803921569\n",
      "neighbors 80\n",
      "[[29  0]\n",
      " [22  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72        29\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.57        51\n",
      "   macro avg       0.28      0.50      0.36        51\n",
      "weighted avg       0.32      0.57      0.41        51\n",
      "\n",
      "0.5686274509803921\n",
      "neighbors 100\n",
      "[[29  0]\n",
      " [22  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72        29\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.57        51\n",
      "   macro avg       0.28      0.50      0.36        51\n",
      "weighted avg       0.32      0.57      0.41        51\n",
      "\n",
      "0.5686274509803921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert text to numbers and find TFIDF\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "# Select training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "neighbors = [1,3,5,8,10,20,50,80,100]\n",
    "for i in range(len(neighbors)):\n",
    "# Train the classification model\n",
    "    classifier = KNeighborsClassifier(n_neighbors=neighbors[i])\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('neighbors ' + str(neighbors[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Modify just the parameter max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features 10\n",
      "[[25  4]\n",
      " [ 8 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81        29\n",
      "           1       0.78      0.64      0.70        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.77      0.75      0.75        51\n",
      "weighted avg       0.77      0.76      0.76        51\n",
      "\n",
      "0.7647058823529411\n",
      "max_features 100\n",
      "[[28  1]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84        29\n",
      "           1       0.92      0.55      0.69        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.83      0.76      0.76        51\n",
      "weighted avg       0.82      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 200\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_features 300\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_features 500\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 800\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 1000\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 1200\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 2000\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "max_features 5000\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n"
     ]
    }
   ],
   "source": [
    "features = [10,100,200,300,500,800,1000,1200,2000,5000]\n",
    "\n",
    "for i in range(len(features)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=features[i], min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model, by default classifier has parameter loss='hinge'\n",
    "    classifier = KNeighborsClassifier(n_neighbors=8)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_features ' + str(features[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Modify just the parameter min_df\n",
    "min_df is used for removing terms that appear too infrequently.\n",
    "- min_df = 5 means \"ignore terms that appear in less than 5 documents\".\n",
    "- The default min_df is 1, which means \"ignore terms that appear in less than 1 document\". Thus, the default setting does not ignore any terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df 1\n",
      "[[28  1]\n",
      " [ 8 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86        29\n",
      "           1       0.93      0.64      0.76        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.86      0.80      0.81        51\n",
      "weighted avg       0.84      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "min_df 10\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "min_df 20\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 30\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "min_df 40\n",
      "[[29  0]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        29\n",
      "           1       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.85      0.73      0.73        51\n",
      "weighted avg       0.83      0.76      0.74        51\n",
      "\n",
      "0.7647058823529411\n",
      "min_df 50\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 80\n",
      "[[27  2]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81        29\n",
      "           1       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.78      0.72      0.72        51\n",
      "weighted avg       0.77      0.75      0.73        51\n",
      "\n",
      "0.7450980392156863\n",
      "min_df 90\n",
      "[[28  1]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        29\n",
      "           1       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.80      0.71      0.71        51\n",
      "weighted avg       0.79      0.75      0.72        51\n",
      "\n",
      "0.7450980392156863\n"
     ]
    }
   ],
   "source": [
    "df_min = [1,10,20,30,40,50,80,90]\n",
    "\n",
    "for i in range(len(df_min)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=df_min[i], max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = KNeighborsClassifier(n_neighbors=8)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('min_df ' + str(df_min[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df 0.1\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 0.2\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 0.3\n",
      "[[29  0]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        29\n",
      "           1       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.78        51\n",
      "   macro avg       0.86      0.75      0.75        51\n",
      "weighted avg       0.84      0.78      0.77        51\n",
      "\n",
      "0.7843137254901961\n",
      "min_df 0.4\n",
      "[[28  1]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81        29\n",
      "           1       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.80      0.71      0.71        51\n",
      "weighted avg       0.79      0.75      0.72        51\n",
      "\n",
      "0.7450980392156863\n",
      "min_df 0.5\n",
      "[[27  2]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81        29\n",
      "           1       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.78      0.72      0.72        51\n",
      "weighted avg       0.77      0.75      0.73        51\n",
      "\n",
      "0.7450980392156863\n",
      "min_df 0.6\n",
      "[[22  7]\n",
      " [14  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68        29\n",
      "           1       0.53      0.36      0.43        22\n",
      "\n",
      "    accuracy                           0.59        51\n",
      "   macro avg       0.57      0.56      0.55        51\n",
      "weighted avg       0.58      0.59      0.57        51\n",
      "\n",
      "0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "df_min = [0.1,0.2,0.3,0.4,0.5,0.6]\n",
    "\n",
    "for i in range(len(df_min)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=df_min[i], max_df=0.7, stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = KNeighborsClassifier(n_neighbors=8)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('min_df ' + str(df_min[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Modify just the parameter max_df\n",
    "max_df is used for removing terms that appear too frequently, also known as \"corpus-specific stop words.\n",
    "- max_df = 25 means \"ignore terms that appear in more than 25 documents\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 1\n",
      "[[ 0 29]\n",
      " [ 0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        29\n",
      "           1       0.43      1.00      0.60        22\n",
      "\n",
      "    accuracy                           0.43        51\n",
      "   macro avg       0.22      0.50      0.30        51\n",
      "weighted avg       0.19      0.43      0.26        51\n",
      "\n",
      "0.43137254901960786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 10\n",
      "[[ 0 29]\n",
      " [ 0 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        29\n",
      "           1       0.43      1.00      0.60        22\n",
      "\n",
      "    accuracy                           0.43        51\n",
      "   macro avg       0.22      0.50      0.30        51\n",
      "weighted avg       0.19      0.43      0.26        51\n",
      "\n",
      "0.43137254901960786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 20\n",
      "[[29  0]\n",
      " [13  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        29\n",
      "           1       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.85      0.70      0.70        51\n",
      "weighted avg       0.82      0.75      0.71        51\n",
      "\n",
      "0.7450980392156863\n",
      "max_df 30\n",
      "[[27  2]\n",
      " [12 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.93      0.79        29\n",
      "           1       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.76      0.69      0.69        51\n",
      "weighted avg       0.75      0.73      0.71        51\n",
      "\n",
      "0.7254901960784313\n",
      "max_df 40\n",
      "[[29  0]\n",
      " [10 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        29\n",
      "           1       1.00      0.55      0.71        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.87      0.77      0.78        51\n",
      "weighted avg       0.85      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 50\n",
      "[[28  1]\n",
      " [11 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.82        29\n",
      "           1       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.82      0.73      0.74        51\n",
      "weighted avg       0.80      0.76      0.75        51\n",
      "\n",
      "0.7647058823529411\n",
      "max_df 80\n",
      "[[28  1]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85        29\n",
      "           1       0.93      0.59      0.72        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.84      0.78      0.79        51\n",
      "weighted avg       0.83      0.80      0.79        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 90\n",
      "[[29  0]\n",
      " [ 9 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        29\n",
      "           1       1.00      0.59      0.74        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.88      0.80      0.80        51\n",
      "weighted avg       0.87      0.82      0.81        51\n",
      "\n",
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "df_max = [1,10,20,30,40,50,80,90]\n",
    "\n",
    "for i in range(len(df_max)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=1, max_df=df_max[i], stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = KNeighborsClassifier(n_neighbors=8)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_df ' + str(df_max[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df 0.1\n",
      "[[19 10]\n",
      " [ 4 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73        29\n",
      "           1       0.64      0.82      0.72        22\n",
      "\n",
      "    accuracy                           0.73        51\n",
      "   macro avg       0.73      0.74      0.73        51\n",
      "weighted avg       0.75      0.73      0.73        51\n",
      "\n",
      "0.7254901960784313\n",
      "max_df 0.2\n",
      "[[20  9]\n",
      " [ 4 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75        29\n",
      "           1       0.67      0.82      0.73        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.75      0.75      0.74        51\n",
      "weighted avg       0.76      0.75      0.75        51\n",
      "\n",
      "0.7450980392156863\n",
      "max_df 0.3\n",
      "[[24  5]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        29\n",
      "           1       0.77      0.77      0.77        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.80      0.80      0.80        51\n",
      "weighted avg       0.80      0.80      0.80        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 0.4\n",
      "[[25  4]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        29\n",
      "           1       0.83      0.91      0.87        22\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.88      0.89      0.88        51\n",
      "weighted avg       0.89      0.88      0.88        51\n",
      "\n",
      "0.8823529411764706\n",
      "max_df 0.5\n",
      "[[25  4]\n",
      " [ 3 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88        29\n",
      "           1       0.83      0.86      0.84        22\n",
      "\n",
      "    accuracy                           0.86        51\n",
      "   macro avg       0.86      0.86      0.86        51\n",
      "weighted avg       0.86      0.86      0.86        51\n",
      "\n",
      "0.8627450980392157\n",
      "max_df 0.6\n",
      "[[22  7]\n",
      " [ 2 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83        29\n",
      "           1       0.74      0.91      0.82        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.83      0.83      0.82        51\n",
      "weighted avg       0.84      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n",
      "max_df 0.7\n",
      "[[22  7]\n",
      " [ 3 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.81        29\n",
      "           1       0.73      0.86      0.79        22\n",
      "\n",
      "    accuracy                           0.80        51\n",
      "   macro avg       0.81      0.81      0.80        51\n",
      "weighted avg       0.82      0.80      0.80        51\n",
      "\n",
      "0.803921568627451\n",
      "max_df 0.8\n",
      "[[29  0]\n",
      " [13  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        29\n",
      "           1       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.75        51\n",
      "   macro avg       0.85      0.70      0.70        51\n",
      "weighted avg       0.82      0.75      0.71        51\n",
      "\n",
      "0.7450980392156863\n",
      "max_df 0.9\n",
      "[[25  4]\n",
      " [ 5 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85        29\n",
      "           1       0.81      0.77      0.79        22\n",
      "\n",
      "    accuracy                           0.82        51\n",
      "   macro avg       0.82      0.82      0.82        51\n",
      "weighted avg       0.82      0.82      0.82        51\n",
      "\n",
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "df_max = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "for i in range(len(df_max)):\n",
    "    # Convert text to numbers and find TFIDF\n",
    "    tfidfconverter = TfidfVectorizer(max_features=300, min_df=0.1, max_df=df_max[i], stop_words=stopwords.words('english'))\n",
    "    x = tfidfconverter.fit_transform(documents).toarray()\n",
    "\n",
    "    # Select training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Train the classification model\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluate the model \n",
    "    print('max_df ' + str(df_max[i]))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
